<!DOCTYPE html>
<html lang>







<head>
	<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<link rel="preconnect" href="//www.googletagmanager.com">
	<link rel="preconnect" href="//zz.bdstatic.com">
	<link rel="preconnect" href="//sp0.baidu.com">
	<link rel="preconnect" href="//www.google-analytics.com">
	<link rel="preconnect" href="//cdn1.lncld.net">
	<link rel="preconnect" href="//unpkg.com">
	<link rel="preconnect" href="//app-router.leancloud.cn">
	<link rel="preconnect" href="//9qpuwspm.api.lncld.net">
	<link rel="preconnect" href="//gravatar.loli.net">

	<title>Exploring Personalized Neural Conversational Models | Road To Surika</title>

	<meta name="HandheldFriendly" content="True">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
	<meta name="generator" content="hexo">
	<meta name="author" content="Surika">
	<meta name="description" content="IJCAI 2017">

	
	<meta name="keywords" content>
	

	
	<link rel="shortcut icon" href="/img/flower.png">
	<link rel="apple-touch-icon" href="/img/flower.png">
	

	
	<meta name="theme-color" content="#3c484e">
	<meta name="msapplication-TileColor" content="#3c484e">
	

	

	

	<meta property="og:site_name" content="Road To Surika">
	<meta property="og:type" content="article">
	<meta property="og:title" content="Exploring Personalized Neural Conversational Models | Road To Surika">
	<meta property="og:description" content="IJCAI 2017">
	<meta property="og:url" content="http://yoursite.com/2020/02/16/Exploring-Personalized-Neural-Conversational-Models/">

	
	<meta property="article:published_time" content="2020-02-16T16:02:00+08:00"> 
	<meta property="article:author" content="Surika">
	<meta property="article:published_first" content="Road To Surika, /2020/02/16/Exploring-Personalized-Neural-Conversational-Models/">
	

	
	
	<link rel="stylesheet" href="/css/allinonecss.min.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

	
	
	
</head>
<body class="post-template">
	<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="site-wrapper">
		




<header class="site-header post-site-header outer">
    <div class="inner">
        
<nav class="site-nav"> 
    <div class="site-nav-left">
        <ul class="nav">
            <li>
                
                
                <a class="site-nav-logo" href="/" title="Road To Surika">
                    <img src="/img/58851587_p0.png" alt="Road To Surika">
                </a>
                
                
            </li>
            
            
            <li>
                <a href="/about" title="ABOUT">ABOUT</a>
            </li>
            
            <li>
                <a href="/archives" title="ARCHIVES">ARCHIVES</a>
            </li>
            
            
        </ul> 
    </div>
    
    <div class="search-button-area">
        <a href="#search" class="search-button">Search ...</a>
    </div>
     
    <div class="site-nav-right">
        
        <a href="#search" class="search-button">Search ...</a>
         
        
<div class="social-links">
    
    
    <a class="social-link" title="github" href="https://github.com/surika" target="_blank" rel="noopener">
        <svg viewbox="0 0 1049 1024" xmlns="http://www.w3.org/2000/svg"><path d="M524.979332 0C234.676191 0 0 234.676191 0 524.979332c0 232.068678 150.366597 428.501342 358.967656 498.035028 26.075132 5.215026 35.636014-11.299224 35.636014-25.205961 0-12.168395-0.869171-53.888607-0.869171-97.347161-146.020741 31.290159-176.441729-62.580318-176.441729-62.580318-23.467619-60.841976-58.234462-76.487055-58.234463-76.487055-47.804409-32.15933 3.476684-32.15933 3.476685-32.15933 53.019436 3.476684 80.83291 53.888607 80.83291 53.888607 46.935238 79.963739 122.553122 57.365291 152.97411 43.458554 4.345855-33.897672 18.252593-57.365291 33.028501-70.402857-116.468925-12.168395-239.022047-57.365291-239.022047-259.012982 0-57.365291 20.860106-104.300529 53.888607-140.805715-5.215026-13.037566-23.467619-66.926173 5.215027-139.067372 0 0 44.327725-13.906737 144.282399 53.888607 41.720212-11.299224 86.917108-17.383422 131.244833-17.383422s89.524621 6.084198 131.244833 17.383422C756.178839 203.386032 800.506564 217.29277 800.506564 217.29277c28.682646 72.1412 10.430053 126.029806 5.215026 139.067372 33.897672 36.505185 53.888607 83.440424 53.888607 140.805715 0 201.64769-122.553122 245.975415-239.891218 259.012982 19.121764 16.514251 35.636014 47.804409 35.636015 97.347161 0 70.402857-0.869171 126.898978-0.869172 144.282399 0 13.906737 9.560882 30.420988 35.636015 25.205961 208.601059-69.533686 358.967656-265.96635 358.967655-498.035028C1049.958663 234.676191 814.413301 0 524.979332 0z"/></svg>
    </a>
    
    
    
    
    
    <a class="social-link" title="bilibili" href="https://space.bilibili.com/177405158" target="_blank" rel="noopener">
        <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M360.896 183.968l-90.912-88.096s-14.208-17.472 9.824-37.248c24.16-19.648 25.376-10.912 33.504-5.472s135.2 130.816 135.2 130.816zm301.952 3.264l90.912-88.096s14.208-17.472-9.824-37.248c-24.032-19.648-25.376-10.912-33.504-5.472s-135.2 130.816-135.2 130.816zM1004 350.336c-3.264-137.984-123.168-164.192-123.168-164.192s-614.336-4.96-742.496 0C10.176 222.304 20 350.336 20 350.336s1.696 274.272-.128 413.12c13.824 138.848 120.864 160.928 120.864 160.928s42.72.864 73.92.864c3.264 8.992 5.696 52.544 54.24 52.544 48.416 0 54.24-52.544 54.24-52.544s354.88-1.696 384.352-1.696c1.696 14.816 8.992 54.976 57.536 54.24 48.416-.864 51.712-57.536 51.712-57.536s16.384-1.696 65.664 0C997.344 898.88 1004 764.192 1004 764.192s-1.568-275.872 0-413.856zm-98.912 439.232c0 21.728-17.248 39.456-38.464 39.456H167.2c-21.248 0-38.464-17.6-38.464-39.456V326.336c0-21.728 17.248-39.456 38.464-39.456h699.424c21.248 0 38.464 17.6 38.464 39.456zM202.4 457.152l205.344-39.456 15.52 77.184-203.648 39.456zm638.976 0l-205.344-39.456-15.648 77.184 203.776 39.456zm-418.08 191.392s45.152 81.312 95.264-26.336c48.416 105.088 101.824 27.904 101.824 27.904l30.336 19.776s-56.672 91.136-131.424 22.208c-63.232 68.928-129.728-21.952-129.728-21.952z"/></svg>
    </a>
    
    
</div>
    </div>
</nav>
    </div>
</header>


<div id="site-main" class="site-main outer" role="main">
    <div class="inner">
        <header class="post-full-header">
            <div class="post-full-meta">
                <time class="post-full-meta-date" datetime="2020-02-16T08:26:23.000Z">
                    2020-02-16
                </time>
                
                <span class="date-divider">/</span>
                
                <a href="/categories/Dialogue-System/">Dialogue System</a>&nbsp;&nbsp;
                
                
            </div>
            <h1 class="post-full-title">Exploring Personalized Neural Conversational Models</h1>
        </header>
        <div class="post-full ">
            
            <figure class="post-full-image" style="background-image: url(/images/45383301_p0.jpg)">
            </figure>
            
            <div class="post-full-content">
                <article id="photoswipe" class="markdown-body">
                    <p>Exploring Personalized Neural Conversational Models</p>
<h1 id="0-Abstract"><a href="#0-Abstract" class="headerlink" title="0.Abstract"></a>0.Abstract</h1><p>对多种显著影响预测效果的因素做了评估，如预训练pretraining、嵌入训练embedding training、数据清理data cleaning、多样性重排序diversity-based raranking、评估设置evaluation setting(retrieval or generative evaluation)，等等。<br>在更大的数据及上pretraining speaker embedding、bootstrapping word and speaker embedding可以显著提升效果（最高3点perplexity），使用MI提升回复多样性对提升ranking metrics(排名指标?)非常有用。</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h1><h1 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2.Related Work"></a>2.Related Work</h1><h1 id="3-Models"><a href="#3-Models" class="headerlink" title="3.Models"></a>3.Models</h1><p>介绍的baseline分为不考虑context/不考虑personalization/二者都不考虑</p>
<h2 id="3-1-Notation"><a href="#3-1-Notation" class="headerlink" title="3.1 Notation"></a>3.1 Notation</h2><p>本文模型训练采用的是<code>有多个对话者参与</code>的数据集。<br>一场对话$C_i$是一个有序集，其中元素是由回合turn $D_i^j$和该回合的说话者speaker $S_i^j$组成的pair。i.e.$C_i={(D_i^1,S_i^1),(D_i^2,S_i^2),…,(D_i^n,S_i^n)}$。每个回合本身是对应说话者所说的words集合，$D_i^j={w^j_{i1},w^j_{i2},…,w^j_{in}}$。为了简洁，在对话中我们无视索引i.所有我们的语言模型基于每个时间步之前的信息预测下一个词的分布。先前不同模型的区别在于使用该回合之前信息的范围(the extent of information)，而我们的工作是比较这些模型。</p>
<h2 id="3-2-GRU"><a href="#3-2-GRU" class="headerlink" title="3.2 GRU"></a>3.2 GRU</h2><h2 id="3-3-Baselines"><a href="#3-3-Baselines" class="headerlink" title="3.3 Baselines"></a>3.3 Baselines</h2><p>本节所有语言模型，等号左边是相同的</p>
<h3 id="3-3-1-Encoder-Decoder"><a href="#3-3-1-Encoder-Decoder" class="headerlink" title="3.3.1 Encoder-Decoder"></a>3.3.1 Encoder-Decoder</h3><p><code>不考虑说话人的信息</code>，是dyadic(二元?)的。也就是说，下一个回复只依赖于当前的对话，独立于其他信息。<br>语言模型：</p>
<script type="math/tex; mode=display">P(w^j_{t+1}|w^j_i,...,w^j_t,D^{-j},S^{-j},S^j) = P(w^j_{t+1}|w^j_1,...,w^j_t,D^{j-1})</script><p>其中，$D^{-j}$指的是直到j的所有turns的集合。即$D^{-j}={D^1,D^2,…,D^{j-1}}$.Speakers $S^{-j}$同理。</p>
<h3 id="3-3-2-Persona-only"><a href="#3-3-2-Persona-only" class="headerlink" title="3.3.2 Persona-only"></a>3.3.2 Persona-only</h3><p>[Li et al., 2016b]<br>引入说话人的信息作为encoder和decoder RNN两边的额外输入。</p>
<script type="math/tex; mode=display">P(w^j_{t+1}|w^j_i,...,w^j_t,D^{-j},S^{-j},S^j) = P(w^j_{t+1}|w^j_1,...,w^j_t,D^{j-1},S^{j-1},S^j)</script><p>。因此，语言模型依赖于当前和之前回合的说话人，在生成新回复时考虑了人格。</p>
<h3 id="3-3-3-Context-only"><a href="#3-3-3-Context-only" class="headerlink" title="3.3.3 Context-only"></a>3.3.3 Context-only</h3><p>Hierarchical Recurrent Encoder-Decoder[Serban et al., 2016b]通过一个每回合更新自己隐藏层，且基于encoder-decoder RNNs的high level,context RNN捕捉上下文线索。但是没有包含任何人格信息。更多细节参考[Serban et al., 2015a].</p>
<script type="math/tex; mode=display">P(w^j_{t+1}|w^j_i,...,w^j_t,D^{-j},S^{-j},S^j) = P(w^j_{t+1}|w^j_1,...,w^j_t,D^{-j})</script><p>注意下一个词依赖于所有之前的回合，进而通过历史保留上下文信息。但是在实践中，上下文被截断，只能考虑过去几个回合的信息。</p>
<h2 id="3-4-CoPerHED-Model"><a href="#3-4-CoPerHED-Model" class="headerlink" title="3.4 CoPerHED Model"></a>3.4 CoPerHED Model</h2><p><strong>Co</strong>ntext-aware, <strong>Per</strong>sona-based <strong>H</strong>ierarchical <strong>E</strong>ncoder-<strong>D</strong>ecoder:混合了persona-based[Li et al., 2016b]和context-aware[Serban et al., 2016b]的神经交流模型。当前回合和之前回合的说话者信息被作为额外信息输入；使用额外的RNN在每个回合水平上总结信息。<br><img alt class="post-img b-lazy" data-img="/images/200216-1.PNG" data-index="0" data-src="/images/200216-1.PNG"></p>
<h3 id="3-4-1-Encoder"><a href="#3-4-1-Encoder" class="headerlink" title="3.4.1 Encoder"></a>3.4.1 Encoder</h3><p>第$j^{th}$回合的隐状态$h^j_t$由每个时间步输入一个词和当前speaker标记得到。所有words和speakers的reperesentation盒模型联合学习。</p>
<script type="math/tex; mode=display">h^j_t = GRU(h^j_{t-1},[w^j_t,s^j])</script><p>本回合说话者人格$s^j$对给定回合的所有时间步固定。</p>
<h3 id="3-4-2-Context-RNN"><a href="#3-4-2-Context-RNN" class="headerlink" title="3.4.2 Context RNN"></a>3.4.2 Context RNN</h3><p>会话中每个回合的句子编码表示由context RNN处理。这有助于保留前一轮的相关信息，并作为预测response的上下文。与[Serban et al., 2016b]类似，CoPerHED由一组分层RNN构成。context RNN工作在turn-level，而language RNN（本例中为GRU）工作在every turn的word-level。<br>$g_j$表示$j^{th}$回合的context RNN的隐状态。</p>
<script type="math/tex; mode=display">g_j = GRU(g_{j-1}, h^j_n)</script><h3 id="3-4-3-Decoder"><a href="#3-4-3-Decoder" class="headerlink" title="3.4.3 Decoder"></a>3.4.3 Decoder</h3><p>输入：当前词语，当前回合speaker，context RNN的隐状态。$\hat{h}_t$表示decoder的隐状态：</p>
<script type="math/tex; mode=display">\hat{h}_t^{j+1} = GRU(\hat{h}_{t-1}^{j+1},[w_t,s^{j+1},g_j])</script><h1 id="4-Datasets"><a href="#4-Datasets" class="headerlink" title="4.Datasets"></a>4.Datasets</h1><p>Movie-Dic<br>TV-Series<br>SubTle</p>
<h1 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5.Experiments"></a>5.Experiments</h1><h2 id="5-1-Data-Preprocessing"><a href="#5-1-Data-Preprocessing" class="headerlink" title="5.1 Data Preprocessing"></a>5.1 Data Preprocessing</h2><h2 id="5-2-Training"><a href="#5-2-Training" class="headerlink" title="5.2 Training"></a>5.2 Training</h2><p>参数介绍。</p>
<ul>
<li>网络：Encoder和Decoder都是两层GRU</li>
<li>dropout:0.2</li>
<li>Adam optimizer</li>
<li>learning rate:0.001(1e-3),10个epoch结束时指数衰减到0.0001(1e-4)，之后保持为常量</li>
<li>梯度剪裁[-5.0, 5.0]</li>
<li>结束条件:hold-out验证集的困惑度饱和</li>
</ul>
<p>最优效果:</p>
<ul>
<li>word embedding size:300</li>
<li>speaker embedding size:50</li>
<li>encoder/decoder GRU 隐单元:300</li>
<li>context GRU隐单元:50</li>
</ul>
<h2 id="5-3-Initialization"><a href="#5-3-Initialization" class="headerlink" title="5.3 Initialization"></a>5.3 Initialization</h2><h3 id="5-3-1-Bootstrap-word-embeddings"><a href="#5-3-1-Bootstrap-word-embeddings" class="headerlink" title="5.3.1 Bootstrap word embeddings"></a>5.3.1 Bootstrap word embeddings</h3><p>使用在大数据集上训练好的word2vec</p>
<h3 id="5-3-2-Bootstrap-speaker-embeddings"><a href="#5-3-2-Bootstrap-speaker-embeddings" class="headerlink" title="5.3.2 Bootstrap speaker embeddings"></a>5.3.2 Bootstrap speaker embeddings</h3><p>使用人工特征初始化speaker embedding。对所有speaker，从训练数据中构建BOW词袋特征，并使用PCA降维。</p>
<h3 id="5-3-3-Pre-train-on-SubTle-dataset"><a href="#5-3-3-Pre-train-on-SubTle-dataset" class="headerlink" title="5.3.3 Pre-train on SubTle dataset"></a>5.3.3 Pre-train on SubTle dataset</h3><p>在标注数据集上微调之前，先使用大规模的数据集预训练，所有speaker分配为$<uns>$，随机指派台词（使用的数据集有剧本）用作预训练的对话。</uns></p>
<h3 id="5-3-4-Model-Varients"><a href="#5-3-4-Model-Varients" class="headerlink" title="5.3.4 Model Varients"></a>5.3.4 Model Varients</h3><h2 id="5-4-Evaluation"><a href="#5-4-Evaluation" class="headerlink" title="5.4 Evaluation"></a>5.4 Evaluation</h2><p>Generation: 困惑度Perplexity<br>Retrieval: Recall@k</p>
<h2 id="5-5-Promoting-diversity-using-MI"><a href="#5-5-Promoting-diversity-using-MI" class="headerlink" title="5.5 Promoting diversity using MI"></a>5.5 Promoting diversity using MI</h2><p>[Li et al., 2016a],打分函数从似然likelihood变成互信息。</p>
<h1 id="6-Results"><a href="#6-Results" class="headerlink" title="6.Results"></a>6.Results</h1><h1 id="7-Discussion-and-Conclusion"><a href="#7-Discussion-and-Conclusion" class="headerlink" title="7.Discussion and Conclusion"></a>7.Discussion and Conclusion</h1><p>实验技巧：</p>
<ol>
<li>在更大的数据集上预训练speaker embedding</li>
<li>bootstrap word and speaker embedding</li>
</ol>
<p>模型:<br>persona-based + context aware,即speaker embedding + context RNN</p>

                </article>
                <ul class="tags-postTags">
                    
                </ul>
            </div>
        </div>
    </div>

    
    <nav id="gobottom" class="pagination">
        
        <a class="prev-post" title="Variational Autoencoder" href="/2020/02/16/Variational-Autoencoder/">
            ← Variational Autoencoder
        </a>
        
        <span class="prev-next-post">·</span>
        
        <a class="next-post" title="AI-Powered Text Generation for Harmonious HumanMachine Interaction Current State and Future Directions" href="/2020/02/15/AI-Powered-Text-Generation-for-Harmonious-HumanMachine-Interaction-Current-State-and-Future-Directions/">
            AI-Powered Text Generation for Harmonious HumanMachine Interaction Current State and Future Directions →
        </a>
        
    </nav>

    
    <div class="inner">
        <div id="comment"></div>
    </div>
    
</div>

<div class="toc-bar">
    <div class="toc-btn-bar">
        <a href="#site-main" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M793.024 710.272a32 32 0 1 0 45.952-44.544l-310.304-320a32 32 0 0 0-46.4 0.48l-297.696 320a32 32 0 0 0 46.848 43.584l274.752-295.328 286.848 295.808z"/></svg>
        </a>
        <div class="toc-btn toc-switch">
            <svg class="toc-open" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M779.776 480h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M779.776 672h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M256 288a32 32 0 1 0 0 64 32 32 0 0 0 0-64M392.576 352h387.2a32 32 0 0 0 0-64h-387.2a32 32 0 0 0 0 64M256 480a32 32 0 1 0 0 64 32 32 0 0 0 0-64M256 672a32 32 0 1 0 0 64 32 32 0 0 0 0-64"/></svg>
            <svg class="toc-close hide" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M512 960c-247.039484 0-448-200.960516-448-448S264.960516 64 512 64 960 264.960516 960 512 759.039484 960 512 960zM512 128.287273c-211.584464 0-383.712727 172.128262-383.712727 383.712727 0 211.551781 172.128262 383.712727 383.712727 383.712727 211.551781 0 383.712727-172.159226 383.712727-383.712727C895.712727 300.415536 723.551781 128.287273 512 128.287273z"/><path d="M557.05545 513.376159l138.367639-136.864185c12.576374-12.416396 12.672705-32.671738 0.25631-45.248112s-32.704421-12.672705-45.248112-0.25631l-138.560301 137.024163-136.447897-136.864185c-12.512727-12.512727-32.735385-12.576374-45.248112-0.063647-12.512727 12.480043-12.54369 32.735385-0.063647 45.248112l136.255235 136.671523-137.376804 135.904314c-12.576374 12.447359-12.672705 32.671738-0.25631 45.248112 6.271845 6.335493 14.496116 9.504099 22.751351 9.504099 8.12794 0 16.25588-3.103239 22.496761-9.247789l137.567746-136.064292 138.687596 139.136568c6.240882 6.271845 14.432469 9.407768 22.65674 9.407768 8.191587 0 16.352211-3.135923 22.591372-9.34412 12.512727-12.480043 12.54369-32.704421 0.063647-45.248112L557.05545 513.376159z"/></svg>
        </div>
        <a href="#gobottom" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M231.424 346.208a32 32 0 0 0-46.848 43.584l297.696 320a32 32 0 0 0 46.4 0.48l310.304-320a32 32 0 1 0-45.952-44.544l-286.848 295.808-274.752-295.36z"/></svg>
        </a>
    </div>
    <div class="toc-main">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#0-Abstract"><span class="toc-text">0.Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-Introduction"><span class="toc-text">1.Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-Related-Work"><span class="toc-text">2.Related Work</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-Models"><span class="toc-text">3.Models</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-Notation"><span class="toc-text">3.1 Notation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-GRU"><span class="toc-text">3.2 GRU</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-Baselines"><span class="toc-text">3.3 Baselines</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-1-Encoder-Decoder"><span class="toc-text">3.3.1 Encoder-Decoder</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-2-Persona-only"><span class="toc-text">3.3.2 Persona-only</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-3-Context-only"><span class="toc-text">3.3.3 Context-only</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-CoPerHED-Model"><span class="toc-text">3.4 CoPerHED Model</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-1-Encoder"><span class="toc-text">3.4.1 Encoder</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-2-Context-RNN"><span class="toc-text">3.4.2 Context RNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-3-Decoder"><span class="toc-text">3.4.3 Decoder</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-Datasets"><span class="toc-text">4.Datasets</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-Experiments"><span class="toc-text">5.Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-Data-Preprocessing"><span class="toc-text">5.1 Data Preprocessing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-Training"><span class="toc-text">5.2 Training</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-Initialization"><span class="toc-text">5.3 Initialization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-1-Bootstrap-word-embeddings"><span class="toc-text">5.3.1 Bootstrap word embeddings</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-2-Bootstrap-speaker-embeddings"><span class="toc-text">5.3.2 Bootstrap speaker embeddings</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-3-Pre-train-on-SubTle-dataset"><span class="toc-text">5.3.3 Pre-train on SubTle dataset</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-4-Model-Varients"><span class="toc-text">5.3.4 Model Varients</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-4-Evaluation"><span class="toc-text">5.4 Evaluation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-5-Promoting-diversity-using-MI"><span class="toc-text">5.5 Promoting diversity using MI</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-Results"><span class="toc-text">6.Results</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7-Discussion-and-Conclusion"><span class="toc-text">7.Discussion and Conclusion</span></a></li></ol>
    </div>
</div>



<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>




	</div>
	


<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
            

<article class="read-next-card" style="background-image: url(/img/73755434_p1.jpg)">
  <header class="read-next-card-header">
    <small class="read-next-card-header-sitetitle">&mdash; Road To Surika &mdash;</small>
    <h3 class="read-next-card-header-title">Recent Posts</h3>
  </header>
  <div class="read-next-divider">
    <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
      <path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/>
    </svg>
  </div>
  <div class="read-next-card-content">
    <ul>
      
      
      
      <li>
        <a href="/2020/02/16/Variational-Autoencoder/">Variational Autoencoder</a>
      </li>
      
      
      
      <li>
        <a href="/2020/02/16/Exploring-Personalized-Neural-Conversational-Models/">Exploring Personalized Neural Conversational Models</a>
      </li>
      
      
      
      <li>
        <a href="/2020/02/15/AI-Powered-Text-Generation-for-Harmonious-HumanMachine-Interaction-Current-State-and-Future-Directions/">AI-Powered Text Generation for Harmonious HumanMachine Interaction Current State and Future Directions</a>
      </li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
  <footer class="read-next-card-footer">
    <a href="/archives">  MORE  → </a>
  </footer>
</article>

            
            
            

<article class="read-next-card" style="background-image: url(/img/73755434_p1.jpg)">
    <header class="read-next-card-header tagcloud-card">
        <h3 class="read-next-card-header-title">Categories</h3>
    </header>
    <div class="read-next-card-content">
        <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithms/">Algorithms</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Anaconda/">Anaconda</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataScience/">DataScience</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/Pytorch/">Pytorch</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Dialogue-System/">Dialogue System</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/Algorithms/">Algorithms</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Lesson/">Lesson</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/Deep-Learning/">Deep Learning</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Pytorch/">Pytorch</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/basis/">basis</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/diary/">diary</a></li></ul>
    </div>
</article>


            
            
            

<article class="read-next-card" style="background-image: url(/img/73755434_p1.jpg)">
	<header class="read-next-card-header tagcloud-card">
		<h3 class="read-next-card-header-title">Tag Cloud</h3>
	</header>
	<div class="read-next-card-content-ext">
		<a href="/tags/Anaconda/" style="font-size: 18px;">Anaconda</a> <a href="/tags/DataScience/" style="font-size: 20px;">DataScience</a> <a href="/tags/Graph/" style="font-size: 18px;">Graph</a> <a href="/tags/Hadoop/" style="font-size: 14px;">Hadoop</a> <a href="/tags/Hbase/" style="font-size: 14px;">Hbase</a> <a href="/tags/Hexo/" style="font-size: 16px;">Hexo</a> <a href="/tags/IPython/" style="font-size: 14px;">IPython</a> <a href="/tags/LaTeX/" style="font-size: 14px;">LaTeX</a> <a href="/tags/Linux/" style="font-size: 14px;">Linux</a> <a href="/tags/MachineLearning/" style="font-size: 14px;">MachineLearning</a> <a href="/tags/NLP/" style="font-size: 16px;">NLP</a> <a href="/tags/Nachos/" style="font-size: 22px;">Nachos</a> <a href="/tags/OperatingSystem/" style="font-size: 22px;">OperatingSystem</a> <a href="/tags/PThreads/" style="font-size: 14px;">PThreads</a> <a href="/tags/Paper/" style="font-size: 14px;">Paper</a> <a href="/tags/ParallelProgramming/" style="font-size: 14px;">ParallelProgramming</a> <a href="/tags/Python/" style="font-size: 14px;">Python</a> <a href="/tags/SDU/" style="font-size: 24px;">SDU</a> <a href="/tags/SSH/" style="font-size: 14px;">SSH</a> <a href="/tags/SoftwareEngineer/" style="font-size: 14px;">SoftwareEngineer</a> <a href="/tags/diary/" style="font-size: 22px;">diary</a> <a href="/tags/python/" style="font-size: 14px;">python</a> <a href="/tags/集体智慧编程/" style="font-size: 14px;">集体智慧编程</a>
	</div>
</article>

            
        </div>
    </div>
</aside>

	




<div id="search" class="search-overlay">
    <div class="search-form">
        
        <div class="search-overlay-logo">
        	<img src="/img/flower.png" alt="Road To Surika">
        </div>
        
        <input id="local-search-input" class="search-input" type="text" name="search" placeholder="Search ...">
        <a class="search-overlay-close" href="#"></a>
    </div>
    <div id="local-search-result"></div>
</div>

<footer class="site-footer outer">
	<div class="site-footer-content inner">
		<div class="copyright">
			<a href="/" title="Road To Surika">Road To Surika &copy; 2020</a>
			
				
			        <span hidden="true" id="/2020/02/16/Exploring-Personalized-Neural-Conversational-Models/" class="leancloud-visitors" data-flag-title="Exploring Personalized Neural Conversational Models">
			            <span>阅读量 </span>
			            <span class="leancloud-visitors-count">0</span>
			        </span>
	    		
    		
		</div>
		<nav class="site-footer-nav">
			
			<a href="https://hexo.io" title="Hexo" target="_blank" rel="noopener">Hexo</a>
			<a href="https://github.com/xzhih/hexo-theme-casper" title="Casper" target="_blank" rel="noopener">Casper</a>
		</nav>
	</div>
</footer>
	


<script>
    if(window.navigator && navigator.serviceWorker) {
        navigator.serviceWorker.getRegistrations().then(function(registrations) {
            for(let registration of registrations) {
                registration.unregister()
            }
        })
    }
</script>


<script id="scriptLoad" src="/js/allinone.min.js" async></script>






<script>
    document.getElementById('scriptLoad').addEventListener('load', function () {
        var bLazy = new Blazy()
    })
</script>







<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>




<script id="valineScript" src="//unpkg.com/valine/dist/Valine.min.js" async></script>
<script>
    document.getElementById('valineScript').addEventListener("load", function() {
        new Valine({
            el: '#comment' ,
            verify: false,
            notify: false,
            appId: '',
            appKey: '',
            placeholder: 'Just go go',
            pageSize: 10,
            avatar: 'mm',
            visitor: true
        })
    });
</script>





<script>
    document.getElementById('scriptLoad').addEventListener('load', function(){
        searchFunc("/")
    });
</script>






<script src="https://cdn.jsdelivr.net/npm/live2d-widget@^3.1.3/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/miku.model.json"},"display":{"superSample":2,"width":300,"height":500,"position":"left","hOffset":0,"vOffset":-10},"mobile":{"show":false,"scale":0.05},"react":{"opacityDefault":1,"opacityOnHover":0.2},"log":false});</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/clicklove.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

